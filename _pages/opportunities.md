---
layout: page
permalink: /opportunities/
title: opportunities
description: Prospective Students
nav: true
nav_order: 5
---



### Are we recruiting?


We are no longer recruiting PhD students, or undergrads. We might be looking for 1-2 Masters students in Fall.
<!-- Yes, we are actively recruiting PhD students in this üçÅ Fall!
<!-- Please keep an eye out for the [announcement of admissions for the PhD Program](https://www.cs.usc.edu/ph-d-application-information/). -->
<!-- Please see below to figure out if [your research interests align with ours](/publications/), and apply to the [USC PhD Admissions](https://www.cs.usc.edu/ph-d-application-information/) by ‚ö° [Dec 15th, 2023](https://days.to/until/15-december) and select [Swabha](https://www.cs.usc.edu/directory/faculty/profile/?lname=Swayamdipta&fname=Swabha) as a potential advisor.
USC has waived GRE scores for graduate admissions and offers [fee waivers](https://gradadm.usc.edu/lightboxes/us-students-fee-waivers/) to select applicants. --> -->

<hr>

<!-- For other students, please see below. -->

### What do we work on?

Here are some questions we have worked on recently:


##### üñãÔ∏è What do we understand about the generative capabilities of language models?

Has language model generation reached a performance saturation or do language models still make systematic errors owing to their design? We studied the [softmax bottleneck](https://arxiv.org/abs/2310.01693) as one concrete limitation and how that affects language generation and justifies truncation sampling. Can we build better language generators?


###### üé® Can language models handle all types of language?
How do language models handle specific distributions of language, such as [ambiguous language](https://arxiv.org/abs/2304.14399), [comparative language](https://arxiv.org/abs/2305.04978) or the language of [explanations](https://arxiv.org/abs/2112.08674)? Can language models generate [structured data](https://arxiv.org/abs/2109.07725)?
<!-- Can we use the lessons above to create high quality datasets, more suitable for modern NLP models? Our work on [Generative Data Augmentation](https://arxiv.org/abs/2004.11546) showed that this is possible to automate to some extent, either via [controlled generation](https://arxiv.org/abs/2105.03023) or [selection](https://arxiv.org/abs/2004.10964). -->


##### üïµüèº‚Äç‚ôÄÔ∏è Are we evaluating the generative capabilities of models rigorously?

What cannot be measured, cannot be improved. Can we reliably compare the generative performance of two different models, in either close-ended generation tasks such as summarization or in open-ended generation? What makes model A better than model B, or are our test sets somewhat misleading us?

<!-- How can we make our [models explain their decisions](https://arxiv.org/abs/2112.08674) to human users, [_intuitively_](https://arxiv.org/abs/2103.01378)? Moreover, as tasks previously considered extremely difficult are getting easier, how do we best [adapt our evaluation methods](https://arxiv.org/abs/2102.01454) to ensure fair evaluation? -->



##### üìö What does our data tell us about our models?

What makes a data collection valuable for instruction tuning or finetuning large language models? Is all human feedback equally valuable under PPO or DPO? Our [Dataset Cartography](https://arxiv.org/abs/2009.10795) offers point estimates, and [V-Information](https://arxiv.org/abs/2110.08420) offers both point and aggregate estimates of data quality. How can we build similar estimates for generative models?

Are all modalities and all data necessary in [multimodal settings](https://arxiv.org/abs/2309.09405)?


##### ü§ñ What can our models reveal about our society?

<!-- Current large scale models tend to [rely on spurious biases to make the correct predictions](https://arxiv.org/abs/1803.02324). The reduction of undesirable biases could be done via data selection, as in [AFLite](https://arxiv.org/abs/2002.04108) or by altering the [learning objectives](https://arxiv.org/abs/1909.03683). However, the discovery of such biases is much trickier and task-dependent.
Going beyond solutions presented in [AFLite](https://arxiv.org/abs/2002.04108), how can we find spurious correlations automatically? -->
<!--
Particularly harmful are social biases in models, such as those which correlate surface markers of certain dialects with subjective attributes such as toxicity. [Social biases cannot be mitigated easily](https://arxiv.org/abs/2102.00086) and require rethinking data collection and task design, as we show in our [latest paper](https://arxiv.org/abs/2111.07997). -->

How far can language models go in helping us understand complex social phenomena such as homelessness? Is it possible to create [collaborative setups between humans and generative models](https://arxiv.org/abs/2201.05955) to this end? What role does [conversational and social context](https://arxiv.org/abs/2306.01985) play in this understanding? Can socio-technical solutions [work well for all](https://arxiv.org/abs/2111.07997)?



<hr>

### Should you send Swabha an email?

Due to the high volume of email, there is very <span style="color:#E7AF06;font-weight:bold">little chance Swabha will be responsive to your email, sorry!</span> See special cases below.
&nbsp;

#### PhD Applicants

<!-- Please wait till later in Fall 2023 for a formal announcements. -->
Due to the high volume of email, there is very little chance we will be able to respond, sorry! However, we will carefully consider every single PhD application we receive.
<!-- However, if you do email Swabha, drop in a few lines about your past research, and why you're interested in working with the DILL Lab. -->
<!-- Swabha will definitely read your email if and when she sees your application. üëÄ -->



#### If you're already at USC:
  * _PhD Students:_ If you think your interests overlap considerably with DILL and would like to collaborate, do email Swabha.
  * _Masters Students:_
    * _RAships:_ We _might_ recruit motivated Masters students with research experience based on availability of time in <span style="color:#E7AF06;font-weight:bold">Spring 2024</span>. If interested in our lab, please email Swabha a copy of your CV and/or a link to your website.
    <!-- While I'm not able to offer any more RAships at the moment, do consider enrolling for [CSCI-699 Data-Centric NLP](https://swabhs.com/csci699-dcnlp/), a class I will be teaching this Fall. This might lead to potential collaborations in the future. Note that class enrollment is not guaranteed for all Masters students. -->
    * _TAships:_ We are not looking for any Masters Students as TAs at the moment.
    * _Undergrads:_ We recruit undergrad researchers almost exclusively through the [CURVE program at USC](https://viterbiundergrad.usc.edu/research/curve/research-positions/computer-science/). We do NOT have any openings for new undergrads in <span style="color:#E7AF06;font-weight:bold">Spring 2024</span>.
  <!-- * _Undergrads:_ Please feel free to email Swabha if you are looking for research opportunities. See other opportunities at [CURVE USC](https://viterbiundergrad.usc.edu/research/curve/research-positions/computer-science/). -->
  <!-- Contact Katie Mills for high school AI research opportunities kmills@usc.edu -->


#### If you're not at USC:
  * _High-school students_: Please consider [K-12 research opportunities at USC](https://www.cs.usc.edu/k-12-outreach/).
  * _Prospective Masters students_: At the moment, we have no openings for you - apologies!
  * _Prospective PhD students_: See above.
  * _Visiting PhD students_: If you think your interests overlap considerably with DILL and would like to collaborate, do email Swabha.
  * _Visiting Undergrads_: At the moment, we have no openings for you - apologies!
  * _Others:_ Swabha might NOT respond if you're looking for recruitment - apologies! Other emails about research questions etc. are welcome, though she might be slow to respond to them.
